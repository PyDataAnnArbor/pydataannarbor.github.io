<!doctype html>
<meta charset="utf-8">
<head>

<link rel="stylesheet" href="/static/normalize.css">
<link rel="stylesheet" href="/static/skeleton.css">
<link rel="stylesheet" href="/static/style.css">
<link rel="stylesheet" href="/static/pygments.css">

<!-- Mobile Specific Metas
–––––––––––––––––––––––––––––––––––––––––––––––––– -->
<meta name="viewport" content="width=device-width, initial-scale=1">

<!-- FONT
–––––––––––––––––––––––––––––––––––––––––––––––––– -->
<link href="//fonts.googleapis.com/css?family=Raleway:400,300,600" rel="stylesheet" type="text/css">

<title>Methods for Interpretable Machine Learning — pydataannarbor.github.io</title>
</head>
<body>
    <div class="container">

        <div class="row">
            <div class="three columns" style="margin-top: 5%">
                <nav>
                    <h3 id="logo"><img src="/static/images/PyDataLogoAnnArbor.png" alt="An image" width="200" height="100"></h3>
                    <ul>
                        <li><a href="/">Index</a></li>
                        
                          <li class="active"><a href="/meetups/">Meetups</a></li>
                        
                        <li><a target="_blank" href="https://twitter.com/pydataannarbor">Twitter</a>
                        <li><a target="_blank" href="https://github.com/pydataannarbor">Github</a>
                    </ul>
                </nav>
                &nbsp;
            </div>

     <div class="nine columns"  style="margin-top: 5%">
       
  
  <div class="blog-post">
  
    <h2>Methods for Interpretable Machine Learning</h2>
  
  <p class="meta">
    written by
    
      Sean Law and Benjamin Zaitlen
    
    on 2018-12-04
  </p>
  <p>Interpretability is the degree to which a human can understand the cause of a decision or prediction. This talk will provide an introduction to model interpretability and its importance in healthcare and other industries. Next, we will discuss models that are interpretable by design, and then delve into obtaining model-agnostic interpretability methods and interpretability of complex models.</p>
<hr>
<p>Haitham Maya is a Data Scientist at JOOL Health. He studied Biomedical Engineering and Statistics at the University of Michigan. Some of his latest work at JOOL has involved designing a coaching platform that delivers recommendations and feedback on people's health and wellbeing.</p>
<p>Brandon Stange is a Data Scientist at JOOL Health. After his Master's in Economics at Central Michigan University, he found his way to healthcare analytics. For the last 8 years, he's worked for providers and health systems, learning and applying analytics to health outcomes. His latest work at JOOL Health has centered around applying various NLP approaches to improve the user experience in their application.</p>
<ul>
<li><a href="https://youtu.be/7-XGllMf2ZI">Meetup Recording</a></li>
<li><a href="https://github.com/PyDataAnnArbor/Meetup/blob/master/talks/2018/20181204/PyData_Model_Interpretability.pdf">Talk PDF</a></li>
</ul>

  </div>


     </div>

<!-- JS
================================================== -->
<script src="http://code.jquery.com/jquery-1.7.1.min.js"></script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-100252062-1', 'auto');
  ga('send', 'pageview');

</script>
</body>
